*****************************************************************

Jon's Work Logs for Mar 21, 2018

*****************************************************************

# Representation of floating point numbers

Can either be normalized or de-normalized

## Normalized
The fraction porition has an implicit leading 1.
I.e anything following will be the decimal after the 1

**Example - 32 bit signed float**
 1 1000 0001 011 0000 0000 0000 0000 0000

Sign: 1
Exponent: 1000 0001
Fraction: 011 0000 0000 0000 0000 0000

**Step 1: calc fraction**
Because this number is big endian (most significant digits first)

take the two 1 digits
`1 * 2^-2` + `1 * 2^-3` = `.375`

add the implicit leading 1:
`1.0` + `0.375` = `1.375`

**Step 2: calc exponent**

Convert the exponent to decimal
`1000 0001` => `129`

In order to show both positive and negative exponents, we have to convert the actual exponent with a bias
In this case we subtract 127 (bias-127) to be able to represent exponents -127 to 128 in 8 bits

**The bias is always set to half of the range to allow representation of both positive and negative exponents**

`129 - 127` = `2`

**Step 3: apply sign bit**
Because the sign bit is 1, it is a negative number

**Result:** `-1.375 * 2 ^ 2 = -5.5`
Note: we always use a radix of 2 for representing binary numbers

## De-normalized
Normalized, due to the leading 1, cannot represent 0

So there is also a denormalized from when the exponent=0

This allows floating points to represent very small (close to 0) positive and negative numbers.

The main thing is that the actual exponent used is always -126, to represent very small numbers!

**Example**
1 0000 0000 011 0000 0000 0000 0000 0000
sign = 1
exponent = 0000 0000
fraction = 011 0000 0000 0000 0000 0000

Because exponent is 0, we use explicit exponent of -126

Fraction = `1 * 2 ^ -2` + `1 * 2 ^ -3` = `-0.375`

**Result** `-0.375 * 2 ^ -126`, which is a very small number equivalent to `-4.4 * 10 ^ -39`

Double precision floating points have 64 bits

**Usually the highest possible exponent, i.e. 1111 1111 111 represents special numbers like +/-Infinity and NaN**

# Character Encoding

Characters are encoded according to a known character encoding scheme. A binary pattern could represent
anything that a computer could represent but known only to a person with the encoding/ decoding scheme.

Most common schemes are:
* 7-bit ASCII (128 characters)
* 8-bit Latix-x (256 chars)
* 16-bit Unicode (65536 chars)

## [UTF-8 (1,112,064 valid chars)](https://www.wikiwand.com/en/UTF-8)

**octet**: 8 bit byte (a sequence of 8 bits), i.e. `0100 1001`

Variable width character encoding (uses 1-4 8 bit bytes based on the character)

Backward compat with ASCII, because the first 128 chars are same as 7-bit ASCII

Compromise between memory/ ability to represent many chars

Prefix bits, other than the 1 byte ascii chars with begin with a `0` and human can determine how many bytes are in the char by counting the leading 1's at the beginning of the first byte

Continuation bytes all start with `10`;  this means that you can never mistake a middle byte in a stream with a byte that begins a character.  When randomly accessing a stream of chars, at most you have to traverse 3 bytes to find the beginning of a character.

i.e. a 2 byte UTF-8 Char `110x xxxx 10xx xxxx`, we know this is 2 bytes because it has 2 leading 1's


# Line Delimiters

Windows/ DOS uses CRLF (CR + LF)
Mac/ Unix uses LF

