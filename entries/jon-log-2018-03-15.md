*****************************************************************

Jon's Work Logs for Mar 15, 2018

*****************************************************************

Three main components of a Data Pipeline

Message Bus -> Data Lake
               Data Warehouse

* Message Bus (i.e. Kafka): low latency inject of events, you can have various consumers subscribed to events, persisting events in memory in Message Bus too expensive for the long term, at this point events are mostly just cleaned and processed before going into Data Lake

* Data Lake (i.e. S3, HDFS): long term storage, on disk, allows you to query objects but no notion of subscribing

* Data Warehouse (best query performance for highest cost): takes some subset of data in Data Lake optimizes it for fast efficient queries.  Does indexing of the data, data structures for efficient lookup, transactions

Before, Spark was just used to publish events from the queue and push them to Data Lake, or to do minimal processing on Data Lake.  But with SparkSQL, it can be used as a Data warehouse solution.

For programming interviews- make sure you understand all constraints of the problem/ inputs/ etc. before moving on.

i.e. counting unique visitors, some events can have the same timestamp.