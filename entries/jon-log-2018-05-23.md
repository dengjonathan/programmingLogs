*****************************************************************

Jon's Work Logs for May 23, 2018

*****************************************************************

# Random Access Memory
* addressable
* sequence of n-bit registers (more bits can hold more data, but fewer addresses)

## Problem space
1. how to use gate logic to store bits persistently over time
2. how do you locate ("address") a specific memory register on which you want to operate

Most of complexity of computer memory can be embedded in low-level sequential gates call **flip-flops**

With computation through binary logic gates and storage build from low-level flip-flops, we have enough to build a full computer.

# Some Theory

In order to remember something, there has to be a concept of *time*

You can only remember something if a piece of data was created **before**

Therefore, a fundamental concept to have computer memory is to have some way of representing time

# Clock

Computers use an oscillator that alternates between two states (tick-tock).  The time between ticks (the beginning of a 0 state to the end of the 1 state) is called a cycle, which is an abstraction of 1 discrete time unit. The current clock phase can be broadcast to other chips simultaneously

